{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_KERAS'] = '2'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG']=':16:8'\n",
    "os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:2'\n",
    "os.environ['TF_DETERMINISTIC_OPS']=\"1\"\n",
    "os.environ[\"TF_USE_LEGACY_KERAS\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 20:15:39.179676: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-28 20:15:39.187811: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-28 20:15:39.197198: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-28 20:15:39.199948: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-28 20:15:39.206903: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-28 20:15:39.686463: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import mmap\n",
    "import os\n",
    "import pathlib\n",
    "import math\n",
    "import random\n",
    "import contextlib\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tf_keras as keras\n",
    "from time import perf_counter\n",
    "from tf_keras import mixed_precision\n",
    "from utils.UtilClass import BitOutputStream, ArithmeticEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722190541.462428   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190541.483790   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190541.483911   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = pathlib.Path(os.getcwd()).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mmap_io(filename: str):\n",
    "    with open(filename, mode=\"rb\") as file_obj:\n",
    "        with mmap.mmap(file_obj.fileno(), length=0, access=mmap.ACCESS_READ) as mmap_obj:\n",
    "            text = mmap_obj.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jul 28 20:15:41 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.06             Driver Version: 535.183.06   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce RTX 4070 ...    On  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   47C    P3              N/A /  55W |     11MiB /  8188MiB |      0%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      2181      G   /usr/lib/xorg/Xorg                            4MiB |\n",
      "+---------------------------------------------------------------------------------------+\n",
      "Num GPUs Available:  1\n",
      "Tensorflow version:  2.17.0\n",
      "MemTotal:       32587652 kB\n",
      "MemFree:         9415980 kB\n",
      "MemAvailable:   25949560 kB\n"
     ]
    }
   ],
   "source": [
    "#@title System Info\n",
    "\n",
    "def system_info():\n",
    "  \"\"\"Prints out system information.\"\"\"\n",
    "  gpu_info = !nvidia-smi\n",
    "  gpu_info = '\\n'.join(gpu_info)\n",
    "  if gpu_info.find('failed') >= 0:\n",
    "    print('Select the Runtime â†’ \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "    print('and then re-execute this cell.')\n",
    "  else:\n",
    "    print(gpu_info)\n",
    "    print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "#   print(\"Pytorch version: \", torch.__version__)\n",
    "  print(\"Tensorflow version: \", tf.__version__)\n",
    "  !lscpu |grep 'Model name'\n",
    "  !cat /proc/meminfo | head -n 3\n",
    "\n",
    "system_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.path.join(ROOT_DIR, 'data', 'ready4cmix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = mmap_io(path)\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "char2idx = {u:i for i, u in enumerate(vocab)}\n",
    "intlist = []\n",
    "for idx, c in enumerate(text):\n",
    "    intlist.append(char2idx[c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of file: 933340281 symbols\n",
      "Vocabulary size: 208\n"
     ]
    }
   ],
   "source": [
    "vocab_size = math.ceil(vocab_size/8) * 8\n",
    "file_len = len(intlist)\n",
    "print ('Length of file: {} symbols'.format(file_len))\n",
    "print ('Vocabulary size: {}'.format(vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "seq_length =  15\n",
    "rnn_units =  2000\n",
    "num_layers = 5\n",
    "embedding_size=1024\n",
    "start_learning_rate = 5e-4\n",
    "end_learning_rate = 2e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#@title Architecture\n",
    "\n",
    "def build_model(vocab_size):\n",
    "    \"\"\"Builds the model architecture.\n",
    "\n",
    "    Args:\n",
    "        vocab_size: Int, size of the vocabulary.\n",
    "    \"\"\"\n",
    "    policy = mixed_precision.Policy('mixed_float16')\n",
    "    mixed_precision.set_global_policy(policy)\n",
    "    inputs = [\n",
    "    keras.Input(batch_input_shape=[batch_size, seq_length])] # shape (256, 15)\n",
    "    # In addition to the primary input, there are also two \"state\" inputs for each\n",
    "    # layer of the network.\n",
    "    for i in range(num_layers):\n",
    "        inputs.append(keras.Input(shape=(None,)))\n",
    "        inputs.append(keras.Input(shape=(None,)))\n",
    "    embedding = keras.layers.Embedding(vocab_size, embedding_size)(inputs[0])\n",
    "    # for idx in inputs:\n",
    "    #     print(idx.shape)\n",
    "    # print(embedding.shape)\n",
    "    # Skip connections will be used to connect each LSTM layer output to the final\n",
    "    # output layer. Each LSTM layer will get as input both the original input and\n",
    "    # the output of the previous layer.\n",
    "    skip_connections = []\n",
    "    # In addition to the softmax output, there are also two \"state\" outputs for\n",
    "    # each layer of the network.\n",
    "    outputs = []\n",
    "    predictions, state_h, state_c = keras.layers.LSTM(rnn_units,\n",
    "                            return_sequences=True,\n",
    "                            return_state=True,\n",
    "                            recurrent_initializer='glorot_uniform',\n",
    "                            )(embedding, initial_state=[\n",
    "                            tf.cast(inputs[1], tf.float16),\n",
    "                            tf.cast(inputs[2], tf.float16)])\n",
    "    skip_connections.append(predictions)\n",
    "    outputs.append(state_h)\n",
    "    outputs.append(state_c)\n",
    "    for i in range(num_layers - 1):\n",
    "        layer_input = keras.layers.concatenate(\n",
    "            [embedding, skip_connections[-1]])\n",
    "        predictions, state_h, state_c = keras.layers.LSTM(rnn_units,\n",
    "            return_sequences=True,\n",
    "            return_state=True,\n",
    "            recurrent_initializer='glorot_uniform')(\n",
    "                layer_input, initial_state=[tf.cast(inputs[i*2+3], tf.float16),\n",
    "                                            tf.cast(inputs[i*2+4], tf.float16)])\n",
    "        skip_connections.append(predictions)\n",
    "        outputs.append(state_h)\n",
    "        outputs.append(state_c)\n",
    "    # The dense output layer only needs to be computed for the last timestep, so\n",
    "    # we can discard the earlier outputs.\n",
    "    last_timestep = []\n",
    "    for i in range(num_layers):\n",
    "        last_timestep.append(tf.slice(skip_connections[i], [0, seq_length - 1, 0],\n",
    "                                    [batch_size, 1, rnn_units]))\n",
    "    if num_layers == 1:\n",
    "        layer_input = last_timestep[0]\n",
    "    else:\n",
    "        layer_input = keras.layers.concatenate(last_timestep)\n",
    "    dense = keras.layers.Dense(vocab_size, name='dense_logits')(layer_input)\n",
    "    output = keras.layers.Activation('softmax', dtype='float32',\n",
    "                                        name='predictions')(dense)\n",
    "    outputs.insert(0, output)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_symbol(index, length, freq, coder, compress, data):\n",
    "    \"\"\"Runs arithmetic coding and returns the next symbol.\n",
    "\n",
    "    Args:\n",
    "    index: Int, position of the symbol in the file.\n",
    "    length: Int, size limit of the file.\n",
    "    freq: ndarray, predicted symbol probabilities.\n",
    "    coder: this is the arithmetic coder.\n",
    "    compress: Boolean, True if compressing, False if decompressing.\n",
    "    data: List containing each symbol in the file.\n",
    "\n",
    "    Returns:\n",
    "    The next symbol, or 0 if \"index\" is over the file size limit.\n",
    "    \"\"\"\n",
    "    symbol = 0\n",
    "    if index < length:\n",
    "        if compress:\n",
    "            symbol = data[index]\n",
    "            coder.write(freq, symbol)\n",
    "        else:\n",
    "            symbol = coder.read(freq)\n",
    "            data[index] = symbol\n",
    "    return symbol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_seed():\n",
    "    \"\"\"Initializes various random seeds to help with determinism.\"\"\"\n",
    "    SEED = 1234\n",
    "    os.environ['PYTHONHASHSEED']=str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    tf.random.set_seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(pos, seq_input, length, vocab_size, coder, model, optimizer, compress,\n",
    "          data, states):\n",
    "    \"\"\"Runs one training step.\n",
    "\n",
    "    Args:\n",
    "    pos: Int, position in the file for the current symbol for the *first* batch.\n",
    "    seq_input: Tensor, containing the last seq_length inputs for the model.\n",
    "    length: Int, size limit of the file.\n",
    "    vocab_size: Int, size of the vocabulary.\n",
    "    coder: this is the arithmetic coder.\n",
    "    model: the model to generate predictions.\n",
    "    optimizer: optimizer used to train the model.\n",
    "    compress: Boolean, True if compressing, False if decompressing.\n",
    "    data: List containing each symbol in the file.\n",
    "    states: List containing state information for the layers of the model.\n",
    "\n",
    "    Returns:\n",
    "    seq_input: Tensor, containing the last seq_length inputs for the model.\n",
    "    cross_entropy: cross entropy numerator.\n",
    "    denom: cross entropy denominator.\n",
    "    \"\"\"\n",
    "    loss = cross_entropy = denom = 0\n",
    "    split = math.ceil(length / batch_size)\n",
    "    # Keep track of operations while running the forward pass for automatic\n",
    "    # differentiation.\n",
    "    with tf.GradientTape() as tape:\n",
    "    # The model inputs contain both seq_input and the states for each layer.\n",
    "        inputs = states.pop(0)\n",
    "        inputs.insert(0, seq_input)\n",
    "        # Run the model (for all batches in parallel) to get predictions for the\n",
    "        # next characters.\n",
    "        outputs = model(inputs)\n",
    "        predictions = outputs.pop(0)\n",
    "        states.append(outputs)\n",
    "        p = predictions.numpy()\n",
    "        symbols = []\n",
    "        # When the last batch reaches the end of the file, we start giving it \"0\"\n",
    "        # as input. We use a mask to prevent this from influencing the gradients.\n",
    "        mask = []\n",
    "        # Go over each batch to run the arithmetic coding and prepare the next\n",
    "        # input.\n",
    "        for i in range(batch_size):\n",
    "            # The \"10000000\" is used to convert floats into large integers (since\n",
    "            # the arithmetic coder works on integers).\n",
    "            freq = np.cumsum(p[i][0] * 10000000 + 1)\n",
    "            index = pos + 1 + i * split\n",
    "            symbol = get_symbol(index, length, freq, coder, compress, data)\n",
    "            symbols.append(symbol)\n",
    "            if index < length:\n",
    "                prob = p[i][0][symbol]\n",
    "                if prob <= 0:\n",
    "                    # Set a small value to avoid error with log2.\n",
    "                    prob = 0.000001\n",
    "                cross_entropy += math.log2(prob)\n",
    "                denom += 1\n",
    "                mask.append(1.0)\n",
    "            else:\n",
    "                mask.append(0.0)\n",
    "        # \"input_one_hot\" will be used both for the loss function and for the next\n",
    "        # input.\n",
    "        input_one_hot = tf.expand_dims(tf.one_hot(symbols, vocab_size), 1)\n",
    "        loss = keras.losses.categorical_crossentropy(\n",
    "            input_one_hot, predictions, from_logits=False) * tf.expand_dims(\n",
    "                tf.convert_to_tensor(mask), 1)\n",
    "        scaled_loss = optimizer.get_scaled_loss(loss)\n",
    "        # Remove the oldest input and append the new one.\n",
    "        seq_input = tf.slice(seq_input, [0, 1],\n",
    "                                [batch_size, seq_length - 1])\n",
    "        seq_input = tf.concat([seq_input, tf.expand_dims(symbols, 1)], 1)\n",
    "    # Run the backwards pass to update model weights.\n",
    "    scaled_gradients = tape.gradient(scaled_loss, model.trainable_variables)\n",
    "    grads = optimizer.get_unscaled_gradients(scaled_gradients)\n",
    "    # Gradient clipping to make training more robust.\n",
    "    capped_grads = [tf.clip_by_norm(grad, 4) for grad in grads]\n",
    "    optimizer.apply_gradients(zip(capped_grads, model.trainable_variables))\n",
    "    return (seq_input, cross_entropy, denom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(compress, length, vocab_size, coder, data):\n",
    "    \"\"\"This runs compression/decompression.\n",
    "\n",
    "    Args:\n",
    "    compress: Boolean, True if compressing, False if decompressing.\n",
    "    length: Int, size limit of the file.\n",
    "    vocab_size: Int, size of the vocabulary.\n",
    "    coder: this is the arithmetic coder.\n",
    "    data: List containing each symbol in the file.\n",
    "    \"\"\"\n",
    "    start = perf_counter()\n",
    "    reset_seed()\n",
    "    model = build_model(vocab_size = vocab_size)\n",
    "    checkpoint_path = tf.train.latest_checkpoint(\n",
    "        os.path.join(ROOT_DIR, 'data', 'checkpoint'))\n",
    "    if checkpoint_path:\n",
    "        model.load_weights(checkpoint_path)\n",
    "    model.summary()\n",
    "    \n",
    "    # Try to split the file into equal size pieces for the different batches. The\n",
    "    # last batch may have fewer characters if the file can't be split equally.\n",
    "    split = math.ceil(length / batch_size)\n",
    "\n",
    "    learning_rate_fn = keras.optimizers.schedules.PolynomialDecay(\n",
    "        start_learning_rate,\n",
    "        split,\n",
    "        end_learning_rate,\n",
    "        power=1.0)\n",
    "    optimizer = keras.optimizers.Adam(\n",
    "        learning_rate=learning_rate_fn,\n",
    "        beta_1=0,\n",
    "        beta_2=0.9999,\n",
    "        epsilon=1e-5)\n",
    "    optimizer = mixed_precision.LossScaleOptimizer(optimizer)\n",
    "    hidden = model.reset_states()\n",
    "    # Use a uniform distribution for predicting the first batch of symbols. The\n",
    "    # \"10000000\" is used to convert floats into large integers (since the\n",
    "    # arithmetic coder works on integers).\n",
    "    freq = np.cumsum(np.full(vocab_size, (1.0 / vocab_size)) * 10000000 + 1)\n",
    "    # Construct the first set of input characters for training.\n",
    "    symbols = []\n",
    "    for i in range(batch_size):\n",
    "        symbols.append(get_symbol(i*split, length, freq, coder, compress, data))\n",
    "    # Replicate the input tensor seq_length times, to match the input format.\n",
    "    seq_input = tf.tile(tf.expand_dims(symbols, 1), [1, seq_length])\n",
    "    pos = cross_entropy = denom = last_output = 0\n",
    "    template = '{:0.2f}%\\tcross entropy: {:0.2f}\\ttime: {:0.2f}'\n",
    "    # This will keep track of layer states. Initialize them to zeros.\n",
    "    states = []\n",
    "    for i in range(seq_length):\n",
    "        states.append([tf.zeros([batch_size, rnn_units])] * (num_layers * 2))\n",
    "    # Keep repeating the training step until we get to the end of the file.\n",
    "    while pos < split:\n",
    "        seq_input, ce, d = train(pos, seq_input, length, vocab_size, coder, model,\n",
    "                                optimizer, compress, data, states)\n",
    "        cross_entropy += ce\n",
    "        denom += d\n",
    "        pos += 1\n",
    "        time_diff = perf_counter() - start\n",
    "        # If it has been over 20 seconds since the last status message, display a\n",
    "        # new one.\n",
    "        if time_diff - last_output > 20:\n",
    "            last_output = time_diff\n",
    "            percentage = 100 * pos / split\n",
    "            if percentage >= 100: continue\n",
    "            print(template.format(percentage, -cross_entropy / denom, time_diff))\n",
    "    if compress:\n",
    "        coder.finish()\n",
    "    print(template.format(100, -cross_entropy / length, time.time() - start))\n",
    "    system_info()\n",
    "    if mode != \"both\" or not compress:\n",
    "        model.save_weights(os.path.join(ROOT_DIR, 'data', 'models'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compress(path):\n",
    "    with open(path, \"wb\") as out, contextlib.closing(BitOutputStream(out)) as bitout:\n",
    "        length = len(intlist)\n",
    "        out.write(length.to_bytes(5, byteorder='big', signed=False))\n",
    "        for i in range(256):\n",
    "            if i in char2idx:\n",
    "                bitout.write(1)\n",
    "            else:\n",
    "                bitout.write(0)\n",
    "        enc = ArithmeticEncoder(32, bitout)\n",
    "        process(True, length, vocab_size, enc, intlist)\n",
    "    print(\"Compressed size:\", os.path.getsize(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Mixed precision compatibility check (mixed_float16): OK\n",
      "Your GPU will likely run quickly with dtype policy mixed_float16 as it has compute capability of at least 7.0. Your GPU: NVIDIA GeForce RTX 4070 Laptop GPU, compute capability 8.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1722190600.299626   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190600.312218   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190600.312357   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190600.312409   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190600.359448   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190600.359554   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "I0000 00:00:1722190600.359626   98373 cuda_executor.cc:1015] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-28 20:16:40.359683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6264 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(256, 15)]                  0         []                            \n",
      "                                                                                                  \n",
      " input_2 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " embedding (Embedding)       (256, 15, 1024)              212992    ['input_1[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast (TFOpLambda)        (None, None)                 0         ['input_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast_1 (TFOpLambda)      (None, None)                 0         ['input_3[0][0]']             \n",
      "                                                                                                  \n",
      " lstm (LSTM)                 [(256, 15, 2000),            2420000   ['embedding[0][0]',           \n",
      "                              (None, None),               0          'tf.cast[0][0]',             \n",
      "                              (None, None)]                          'tf.cast_1[0][0]']           \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_5 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)   (256, 15, 3024)              0         ['embedding[0][0]',           \n",
      "                                                                     'lstm[0][0]']                \n",
      "                                                                                                  \n",
      " tf.cast_2 (TFOpLambda)      (None, None)                 0         ['input_4[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast_3 (TFOpLambda)      (None, None)                 0         ['input_5[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_1 (LSTM)               [(256, 15, 2000),            4020000   ['concatenate[0][0]',         \n",
      "                              (None, None),               0          'tf.cast_2[0][0]',           \n",
      "                              (None, None)]                          'tf.cast_3[0][0]']           \n",
      "                                                                                                  \n",
      " input_6 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_7 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (256, 15, 3024)              0         ['embedding[0][0]',           \n",
      " )                                                                   'lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.cast_4 (TFOpLambda)      (None, None)                 0         ['input_6[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast_5 (TFOpLambda)      (None, None)                 0         ['input_7[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_2 (LSTM)               [(256, 15, 2000),            4020000   ['concatenate_1[0][0]',       \n",
      "                              (None, None),               0          'tf.cast_4[0][0]',           \n",
      "                              (None, None)]                          'tf.cast_5[0][0]']           \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_9 (InputLayer)        [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate  (256, 15, 3024)              0         ['embedding[0][0]',           \n",
      " )                                                                   'lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " tf.cast_6 (TFOpLambda)      (None, None)                 0         ['input_8[0][0]']             \n",
      "                                                                                                  \n",
      " tf.cast_7 (TFOpLambda)      (None, None)                 0         ['input_9[0][0]']             \n",
      "                                                                                                  \n",
      " lstm_3 (LSTM)               [(256, 15, 2000),            4020000   ['concatenate_2[0][0]',       \n",
      "                              (None, None),               0          'tf.cast_6[0][0]',           \n",
      "                              (None, None)]                          'tf.cast_7[0][0]']           \n",
      "                                                                                                  \n",
      " input_10 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)       [(None, None)]               0         []                            \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate  (256, 15, 3024)              0         ['embedding[0][0]',           \n",
      " )                                                                   'lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.cast_8 (TFOpLambda)      (None, None)                 0         ['input_10[0][0]']            \n",
      "                                                                                                  \n",
      " tf.cast_9 (TFOpLambda)      (None, None)                 0         ['input_11[0][0]']            \n",
      "                                                                                                  \n",
      " lstm_4 (LSTM)               [(256, 15, 2000),            4020000   ['concatenate_3[0][0]',       \n",
      "                              (None, None),               0          'tf.cast_8[0][0]',           \n",
      "                              (None, None)]                          'tf.cast_9[0][0]']           \n",
      "                                                                                                  \n",
      " tf.slice (TFOpLambda)       (256, 1, 2000)               0         ['lstm[0][0]']                \n",
      "                                                                                                  \n",
      " tf.slice_1 (TFOpLambda)     (256, 1, 2000)               0         ['lstm_1[0][0]']              \n",
      "                                                                                                  \n",
      " tf.slice_2 (TFOpLambda)     (256, 1, 2000)               0         ['lstm_2[0][0]']              \n",
      "                                                                                                  \n",
      " tf.slice_3 (TFOpLambda)     (256, 1, 2000)               0         ['lstm_3[0][0]']              \n",
      "                                                                                                  \n",
      " tf.slice_4 (TFOpLambda)     (256, 1, 2000)               0         ['lstm_4[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate  (256, 1, 10000)              0         ['tf.slice[0][0]',            \n",
      " )                                                                   'tf.slice_1[0][0]',          \n",
      "                                                                     'tf.slice_2[0][0]',          \n",
      "                                                                     'tf.slice_3[0][0]',          \n",
      "                                                                     'tf.slice_4[0][0]']          \n",
      "                                                                                                  \n",
      " dense_logits (Dense)        (256, 1, 208)                2080208   ['concatenate_4[0][0]']       \n",
      "                                                                                                  \n",
      " predictions (Activation)    (256, 1, 208)                0         ['dense_logits[0][0]']        \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 187293200 (714.47 MB)\n",
      "Trainable params: 187293200 (714.47 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-28 20:16:42.911950: E tensorflow/core/util/util.cc:131] oneDNN supports DT_HALF only on platforms with AVX-512. Falling back to the default Eigen-based implementation if present.\n",
      "2024-07-28 20:16:42.977086: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 8907\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1722190606.557915   98373 service.cc:146] XLA service 0x56441db84360 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1722190606.557930   98373 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 4070 Laptop GPU, Compute Capability 8.9\n",
      "2024-07-28 20:16:46.561688: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1722190606.709978   98373 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function _BaseOptimizer._update_step_xla at 0x7792a44ff010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function _BaseOptimizer._update_step_xla at 0x7792a44ff010> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "0.00%\tcross entropy: 8.23\ttime: 20.99\n",
      "0.00%\tcross entropy: 7.14\ttime: 41.58\n",
      "0.00%\tcross entropy: 6.62\ttime: 61.86\n",
      "0.00%\tcross entropy: 6.51\ttime: 96.11\n",
      "0.00%\tcross entropy: 6.45\ttime: 122.80\n",
      "0.00%\tcross entropy: 6.25\ttime: 144.84\n",
      "0.00%\tcross entropy: 6.10\ttime: 165.54\n",
      "0.00%\tcross entropy: 5.99\ttime: 189.58\n",
      "0.00%\tcross entropy: 5.91\ttime: 221.95\n",
      "0.00%\tcross entropy: 5.90\ttime: 250.36\n",
      "0.00%\tcross entropy: 5.83\ttime: 271.53\n",
      "0.00%\tcross entropy: 5.75\ttime: 293.38\n",
      "0.00%\tcross entropy: 5.69\ttime: 318.38\n",
      "0.00%\tcross entropy: 5.66\ttime: 346.78\n",
      "0.00%\tcross entropy: 5.63\ttime: 373.84\n",
      "0.00%\tcross entropy: 5.58\ttime: 395.70\n",
      "0.00%\tcross entropy: 5.52\ttime: 422.55\n",
      "0.00%\tcross entropy: 5.50\ttime: 443.66\n",
      "0.00%\tcross entropy: 5.49\ttime: 479.11\n",
      "0.00%\tcross entropy: 5.46\ttime: 500.60\n",
      "0.00%\tcross entropy: 5.43\ttime: 521.39\n",
      "0.00%\tcross entropy: 5.39\ttime: 550.03\n",
      "0.00%\tcross entropy: 5.38\ttime: 580.77\n",
      "0.00%\tcross entropy: 5.36\ttime: 616.12\n",
      "0.00%\tcross entropy: 5.34\ttime: 637.48\n",
      "0.00%\tcross entropy: 5.31\ttime: 664.04\n",
      "0.00%\tcross entropy: 5.28\ttime: 694.47\n",
      "0.00%\tcross entropy: 5.27\ttime: 716.21\n",
      "0.00%\tcross entropy: 5.25\ttime: 740.79\n",
      "0.00%\tcross entropy: 5.24\ttime: 761.45\n",
      "0.00%\tcross entropy: 5.22\ttime: 783.00\n",
      "0.00%\tcross entropy: 5.21\ttime: 831.80\n",
      "0.00%\tcross entropy: 5.19\ttime: 854.04\n",
      "0.00%\tcross entropy: 5.17\ttime: 882.90\n",
      "0.00%\tcross entropy: 5.15\ttime: 909.45\n",
      "0.00%\tcross entropy: 5.14\ttime: 955.97\n",
      "0.00%\tcross entropy: 5.13\ttime: 981.80\n",
      "0.00%\tcross entropy: 5.12\ttime: 1005.34\n",
      "0.00%\tcross entropy: 5.10\ttime: 1036.58\n",
      "0.00%\tcross entropy: 5.10\ttime: 1076.33\n",
      "0.00%\tcross entropy: 5.08\ttime: 1099.17\n",
      "0.00%\tcross entropy: 5.06\ttime: 1129.41\n",
      "0.00%\tcross entropy: 5.05\ttime: 1156.54\n",
      "0.00%\tcross entropy: 5.04\ttime: 1196.07\n",
      "0.00%\tcross entropy: 5.03\ttime: 1224.63\n",
      "0.00%\tcross entropy: 5.02\ttime: 1251.91\n",
      "0.00%\tcross entropy: 5.01\ttime: 1302.69\n",
      "0.00%\tcross entropy: 4.99\ttime: 1339.53\n",
      "0.00%\tcross entropy: 4.98\ttime: 1410.35\n",
      "0.00%\tcross entropy: 4.97\ttime: 1441.86\n",
      "0.00%\tcross entropy: 4.96\ttime: 1471.77\n",
      "0.00%\tcross entropy: 4.95\ttime: 1538.42\n",
      "0.01%\tcross entropy: 4.93\ttime: 1568.61\n",
      "0.01%\tcross entropy: 4.92\ttime: 1600.11\n",
      "0.01%\tcross entropy: 4.92\ttime: 1645.39\n",
      "0.01%\tcross entropy: 4.91\ttime: 1665.44\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m path_to_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(ROOT_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompressed.dat\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m \u001b[43mcompress\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_to_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[17], line 11\u001b[0m, in \u001b[0;36mcompress\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      9\u001b[0m             bitout\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     10\u001b[0m     enc \u001b[38;5;241m=\u001b[39m ArithmeticEncoder(\u001b[38;5;241m32\u001b[39m, bitout)\n\u001b[0;32m---> 11\u001b[0m     \u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mintlist\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompressed size:\u001b[39m\u001b[38;5;124m\"\u001b[39m, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mgetsize(path))\n",
      "Cell \u001b[0;32mIn[16], line 54\u001b[0m, in \u001b[0;36mprocess\u001b[0;34m(compress, length, vocab_size, coder, data)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;66;03m# Keep repeating the training step until we get to the end of the file.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m pos \u001b[38;5;241m<\u001b[39m split:\n\u001b[0;32m---> 54\u001b[0m     seq_input, ce, d \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseq_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvocab_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcoder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m                            \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcompress\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     56\u001b[0m     cross_entropy \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m ce\n\u001b[1;32m     57\u001b[0m     denom \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m d\n",
      "Cell \u001b[0;32mIn[15], line 75\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(pos, seq_input, length, vocab_size, coder, model, optimizer, compress, data, states)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;66;03m# Gradient clipping to make training more robust.\u001b[39;00m\n\u001b[1;32m     74\u001b[0m capped_grads \u001b[38;5;241m=\u001b[39m [tf\u001b[38;5;241m.\u001b[39mclip_by_norm(grad, \u001b[38;5;241m4\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m grads]\n\u001b[0;32m---> 75\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcapped_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainable_variables\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (seq_input, cross_entropy, denom)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/mixed_precision/loss_scale_optimizer.py:1343\u001b[0m, in \u001b[0;36mLossScaleOptimizerV3.apply_gradients\u001b[0;34m(self, grads_and_vars, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1340\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_fn\u001b[39m():\n\u001b[1;32m   1341\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_gradients(grads, wrapped_vars)\n\u001b[0;32m-> 1343\u001b[0m     \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msmart_cond\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1344\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshould_apply_grads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_not_apply_fn\u001b[49m\n\u001b[1;32m   1345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1348\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_gradients_cross_replica\u001b[39m(\n\u001b[1;32m   1349\u001b[0m         distribution, grads, wrapped_vars\n\u001b[1;32m   1350\u001b[0m     ):\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/framework/smart_cond.py:53\u001b[0m, in \u001b[0;36msmart_cond\u001b[0;34m(pred, true_fn, false_fn, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pred_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m pred_value:\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrue_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     55\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m false_fn()\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/mixed_precision/loss_scale_optimizer.py:1341\u001b[0m, in \u001b[0;36mLossScaleOptimizerV3.apply_gradients.<locals>.apply_fn\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1340\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_fn\u001b[39m():\n\u001b[0;32m-> 1341\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_vars\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/mixed_precision/loss_scale_optimizer.py:1373\u001b[0m, in \u001b[0;36mLossScaleOptimizerV3._apply_gradients\u001b[0;34m(self, grads, wrapped_vars)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply_gradients\u001b[39m(\u001b[38;5;28mself\u001b[39m, grads, wrapped_vars):\n\u001b[1;32m   1371\u001b[0m     \u001b[38;5;66;03m# Pass skip_gradients_aggregation=True since LossScaleOptimizer\u001b[39;00m\n\u001b[1;32m   1372\u001b[0m     \u001b[38;5;66;03m# already aggregated the gradients.\u001b[39;00m\n\u001b[0;32m-> 1373\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1374\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwrapped_vars\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mskip_gradients_aggregation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1376\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1300\u001b[0m, in \u001b[0;36mOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name, skip_gradients_aggregation, **kwargs)\u001b[0m\n\u001b[1;32m   1298\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_gradients_aggregation \u001b[38;5;129;01mand\u001b[39;00m experimental_aggregate_gradients:\n\u001b[1;32m   1299\u001b[0m     grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maggregate_gradients(grads_and_vars)\n\u001b[0;32m-> 1300\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:729\u001b[0m, in \u001b[0;36m_BaseOptimizer.apply_gradients\u001b[0;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply_weight_decay(trainable_variables)\n\u001b[1;32m    728\u001b[0m grads_and_vars \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(grads, trainable_variables))\n\u001b[0;32m--> 729\u001b[0m iteration \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_apply_gradients\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    731\u001b[0m \u001b[38;5;66;03m# Apply variable constraints after applying gradients.\u001b[39;00m\n\u001b[1;32m    732\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m variable \u001b[38;5;129;01min\u001b[39;00m trainable_variables:\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1330\u001b[0m, in \u001b[0;36mOptimizer._internal_apply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mesh \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_run_with_dtensor:\n\u001b[1;32m   1327\u001b[0m     \u001b[38;5;66;03m# Skip any usage of strategy logic for DTensor\u001b[39;00m\n\u001b[1;32m   1328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m_internal_apply_gradients(grads_and_vars)\n\u001b[0;32m-> 1330\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__internal__\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmaybe_merge_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distributed_apply_gradients_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1332\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_distribution_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads_and_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1334\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/distribute/merge_call_interim.py:51\u001b[0m, in \u001b[0;36mmaybe_merge_call\u001b[0;34m(fn, strategy, *args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Maybe invoke `fn` via `merge_call` which may or may not be fulfilled.\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \n\u001b[1;32m     33\u001b[0m \u001b[38;5;124;03mThe caller of this utility function requests to invoke `fn` via `merge_call`\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;124;03m  The return value of the `fn` call.\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m strategy_supports_no_merge_call():\n\u001b[0;32m---> 51\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstrategy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m distribute_lib\u001b[38;5;241m.\u001b[39mget_replica_context()\u001b[38;5;241m.\u001b[39mmerge_call(\n\u001b[1;32m     54\u001b[0m       fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1422\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn\u001b[0;34m(self, distribution, grads_and_vars, **kwargs)\u001b[0m\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n\u001b[1;32m   1421\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m grad, var \u001b[38;5;129;01min\u001b[39;00m grads_and_vars:\n\u001b[0;32m-> 1422\u001b[0m     \u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextended\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1423\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapply_grad_to_update_var\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m   1424\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39muse_ema:\n\u001b[1;32m   1427\u001b[0m     _, var_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mgrads_and_vars)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:3005\u001b[0m, in \u001b[0;36mStrategyExtendedV2.update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   3002\u001b[0m   fn \u001b[38;5;241m=\u001b[39m autograph\u001b[38;5;241m.\u001b[39mtf_convert(\n\u001b[1;32m   3003\u001b[0m       fn, autograph_ctx\u001b[38;5;241m.\u001b[39mcontrol_status_ctx(), convert_by_default\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   3004\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_container_strategy()\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m-> 3005\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3006\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3007\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replica_ctx_update(\n\u001b[1;32m   3008\u001b[0m       var, fn, args\u001b[38;5;241m=\u001b[39margs, kwargs\u001b[38;5;241m=\u001b[39mkwargs, group\u001b[38;5;241m=\u001b[39mgroup)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4075\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update\u001b[0;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[1;32m   4072\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update\u001b[39m(\u001b[38;5;28mself\u001b[39m, var, fn, args, kwargs, group):\n\u001b[1;32m   4073\u001b[0m   \u001b[38;5;66;03m# The implementations of _update() and _update_non_slot() are identical\u001b[39;00m\n\u001b[1;32m   4074\u001b[0m   \u001b[38;5;66;03m# except _update() passes `var` as the first argument to `fn()`.\u001b[39;00m\n\u001b[0;32m-> 4075\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_non_slot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroup\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/distribute/distribute_lib.py:4081\u001b[0m, in \u001b[0;36m_DefaultDistributionExtended._update_non_slot\u001b[0;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[1;32m   4077\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_non_slot\u001b[39m(\u001b[38;5;28mself\u001b[39m, colocate_with, fn, args, kwargs, should_group):\n\u001b[1;32m   4078\u001b[0m   \u001b[38;5;66;03m# TODO(josh11b): Figure out what we should be passing to UpdateContext()\u001b[39;00m\n\u001b[1;32m   4079\u001b[0m   \u001b[38;5;66;03m# once that value is used for something.\u001b[39;00m\n\u001b[1;32m   4080\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m UpdateContext(colocate_with):\n\u001b[0;32m-> 4081\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4082\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m should_group:\n\u001b[1;32m   4083\u001b[0m       \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py:596\u001b[0m, in \u001b[0;36mcall_with_unspecified_conversion_status.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    595\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m ag_ctx\u001b[38;5;241m.\u001b[39mControlStatusCtx(status\u001b[38;5;241m=\u001b[39mag_ctx\u001b[38;5;241m.\u001b[39mStatus\u001b[38;5;241m.\u001b[39mUNSPECIFIED):\n\u001b[0;32m--> 596\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/optimizers/optimizer.py:1417\u001b[0m, in \u001b[0;36mOptimizer._distributed_apply_gradients_fn.<locals>.apply_grad_to_update_var\u001b[0;34m(var, grad)\u001b[0m\n\u001b[1;32m   1415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_grad_to_update_var\u001b[39m(var, grad):\n\u001b[1;32m   1416\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjit_compile:\n\u001b[0;32m-> 1417\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_update_step_xla\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgrad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mid\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_var_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1418\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1419\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_step(grad, var)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:132\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    130\u001b[0m args \u001b[38;5;241m=\u001b[39m args \u001b[38;5;28;01mif\u001b[39;00m args \u001b[38;5;28;01melse\u001b[39;00m ()\n\u001b[1;32m    131\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m--> 132\u001b[0m function \u001b[38;5;241m=\u001b[39m \u001b[43mtrace_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;66;03m# Bind it ourselves to skip unnecessary canonicalization of default call.\u001b[39;00m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:178\u001b[0m, in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    175\u001b[0m     args \u001b[38;5;241m=\u001b[39m tracing_options\u001b[38;5;241m.\u001b[39minput_signature\n\u001b[1;32m    176\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m--> 178\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    179\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtracing_options\u001b[49m\n\u001b[1;32m    180\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mbind_graph_to_function:\n\u001b[1;32m    183\u001b[0m   concrete_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:239\u001b[0m, in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    229\u001b[0m lookup_func_type, lookup_func_context \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    230\u001b[0m     function_type_utils\u001b[38;5;241m.\u001b[39mmake_canonicalized_monomorphic_type(\n\u001b[1;32m    231\u001b[0m         args,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    235\u001b[0m     )\n\u001b[1;32m    236\u001b[0m )\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tracing_options\u001b[38;5;241m.\u001b[39mfunction_cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 239\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_options\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_cache\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlookup\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m      \u001b[49m\u001b[43mlookup_func_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_func_context\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    243\u001b[0m   concrete_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_cache.py:48\u001b[0m, in \u001b[0;36mFunctionCache.lookup\u001b[0;34m(self, function_type, context)\u001b[0m\n\u001b[1;32m     46\u001b[0m context \u001b[38;5;241m=\u001b[39m context \u001b[38;5;129;01mor\u001b[39;00m FunctionContext()\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m context \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_dict:\n\u001b[0;32m---> 48\u001b[0m   dispatch_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dispatch_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunction_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m dispatch_type:\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_primary[(context, dispatch_type)]\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/type_dispatch.py:92\u001b[0m, in \u001b[0;36mTypeDispatchTable.dispatch\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m     89\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m     91\u001b[0m most_specific_supertype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m other \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dispatch_table:\n\u001b[1;32m     93\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m request\u001b[38;5;241m.\u001b[39mis_supertype_of(other):\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m most_specific_supertype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m other\u001b[38;5;241m.\u001b[39mis_supertype_of(\n\u001b[1;32m     95\u001b[0m         most_specific_supertype):\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:452\u001b[0m, in \u001b[0;36mFunctionType.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, FunctionType):\n\u001b[1;32m    450\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptures\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tensorflow/core/function/polymorphism/function_type.py:150\u001b[0m, in \u001b[0;36mParameter.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(other, Parameter):\n\u001b[1;32m    148\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m--> 150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m         \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptional\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m                                   \u001b[49m\u001b[43mother\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtype_constraint\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.virtualenvs/compression/lib/python3.10/site-packages/tf_keras/src/mixed_precision/autocast_variable.py:71\u001b[0m, in \u001b[0;36mAutoCastVariableSpec.__eq__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__hash__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mhash\u001b[39m(\u001b[38;5;28mid\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_value))\n\u001b[0;32m---> 71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__eq__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m other\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "path_to_file = os.path.join(ROOT_DIR, \"data\", \"compressed.dat\")\n",
    "compress(path_to_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compression",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
